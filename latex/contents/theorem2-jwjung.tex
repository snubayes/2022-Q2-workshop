
이제 어떤 상수 $c_1>0$가 존재하여 모든 $i=1, \dots, r$에 대해
\[
\|\overline{\mathbb{P}}_{i,0}\wedge \overline{\mathbb{P}}_{i,1}\| \ge c_1
\]
임을 보이면 되는데 여기서는 $\|\overline{\mathbb{P}}_{1,0}\wedge \overline{\mathbb{P}}_{1,1}\| \ge c_1$, 즉 $i=1$일 때 만을 보일 것이다. $i$가 바뀌어도 동일한 상수 $c_1$을 얻을 수 있기에 이것만으로 충분하다. \newline

먼저 다음과 같은 변수 공간들을 고려하자.

\[
\Lambda_1 := \{ \lambda_1 (\theta) \in \mathbb{R}^p \ : \ \theta\in\Theta\}, \quad \Lambda_{-1}:= \{ \lambda_{-1}(\theta) \equiv (\lambda_2(\theta), \dots, \lambda_r(\theta))^T \in \mathbb{R}^{(r-1)\times p} \ : \ \theta\in\Theta\}. 
\]
각 $a \in \{0,1\}$, $b\in\{0,1\}^{r-1}$, $c\in \Lambda_{-1}$마다 다음과 같은 확률분포를 정의한다:
\[
\overline{\mathbb{P}}_{(1,a,b,c)} := \frac{1}{|\Theta_{(1,a,b,c)}|} \sum_{\theta \in \Theta_{(1,a,b,c)}} \mathbb{P}_\theta, \quad \Theta_{(1,a,b,c)} :=  \{\theta\in\Theta \ : \ \gamma_1(\theta) = a, \quad \gamma_{-1}(\theta) = b, \quad \lambda_{-1}(\theta) = c\}.
\]
여기서 $\gamma_{-1}(\theta) = (\gamma_2(\theta), \dots, \gamma_r(\theta))^T$ 이다. 이제 함수 $f= f(\gamma_{-1}, \lambda_{-1})$를 $\Theta_{-1}:= \{0,1\}^{r-1}\times\Lambda_{-1}$ 에서 평균을 취한 값을 $\mathbb{E}_{(\gamma_{-1}, \lambda_{-1})}f(\gamma_{-1}, \lambda_{-1})$라고 쓴다. 즉
\[
\mathbb{E}_{(\gamma_{-1}, \lambda_{-1})}f(\gamma_{-1}, \lambda_{-1}) := \frac{1}{2^{r-1}|\Lambda|} \sum_{(b,c)\in \Theta_{-1}} |\Theta_{(1,a,b,c)}| f(b,c)
\]
이고 $a$는 0과 1 중 무엇을 선택해도 무관하다.\\

이제 어떤 상수 $c_2\in(0,1)$가 존재하여

\begin{equation}\label{16}\tag{16}
\mathbb{E}_{(\gamma_{-1}, \lambda_{-1})}\left\{ \int \left(\frac{d\overline{\mathbb{P}}_{(1,1,\gamma_{-1}, \lambda_{-1})} }{d\overline{\mathbb{P}}_{(1,0,\gamma_{-1}, \lambda_{-1})} } \right)^2 d\overline{\mathbb{P}}_{(1,0,\gamma_{-1}, \lambda_{-1})} -1 \right\} \le c_2^2
\end{equation}
임을 보이기만 하면 충분하다. 왜냐하면 \cite[Lemma 8, (ii)]{cai2012optimal}의 결과를 이용하면 위 식은
\[
\| \overline{\mathbb{P}}_{1,0}\wedge \overline{\mathbb{P}}_{1,1} \| \ge 1-c_2 >0
\]
을 의미하기 때문이다. \\

\begin{quote}
여기서 잠시 이에 대한 증명을 짚고 넘어가자면, 우선 공통의 dominating measure $\mu$에 대해 두 개의 density $q_0$와 $q_1$가 있다고 할 때 옌센 부등식을 이용하면

\[
\left[ \int |q_0-q_1| d\mu\right]^2 = \left( \int \left|\frac{q_0 - q_1}{q_1} \right| q_1 \right)^2 \le \int \frac{(q_0 - q_1)^2}{q_1} d\mu   = \int \left(\frac{q_0^2}{q_1} -1 \right)d\mu
\]
이다. 위 식과 \eqref{16}을 이용하면 알 수 있는 사실은

\[
\mathbb{E}_{(\gamma_{-1}, \lambda_{-1})}\left\{ \int \left| d\overline{\mathbb{P}}_{(1,1,\gamma_{-1}, \lambda_{-1})} - d\overline{\mathbb{P}}_{(1,0,\gamma_{-1}, \lambda_{-1})}  \right|^2 \right\} \le c_2^2
\]
이고 코시-슈바르츠 부등식을 이용하면 

\[
\mathbb{E}_{(\gamma_{-1}, \lambda_{-1})}\left\{ \int \left| d\overline{\mathbb{P}}_{(1,1,\gamma_{-1}, \lambda_{-1})} - d\overline{\mathbb{P}}_{(1,0,\gamma_{-1}, \lambda_{-1})}  \right| \right\} \le c_2
\]
또한 성립함을 알 수 있다. 여기서 total variation affinity
\[
\| \mathbb{P} \wedge \mathbb{Q}\| = 1- TV(\mathbb{P} , \mathbb{Q})
\]
를 이용하면 결국
\[
\mathbb{E}_{(\gamma_{-1}, \lambda_{-1})}\left\{ \left\| \overline{\mathbb{P}}_{(1,1,\gamma_{-1}, \lambda_{-1})} \wedge \overline{\mathbb{P}}_{(1,0,\gamma_{-1}, \lambda_{-1})}  \right\| \right\} \ge 1- c_2
\]
를 얻게 된다. 마지막으로 $\overline{\mathbb{P}}_{1,0}$와  $\overline{\mathbb{P}}_{1,1}$가 각각 $\overline{\mathbb{P}}_{(1,0,\gamma_{-1}, \lambda_{-1})}$, $\overline{\mathbb{P}}_{(1,1,\gamma_{-1}, \lambda_{-1})}$와 같은 형태의 확률측도들에 대한 가중평균이라는 점을 기억한다면, \cite[Lemma 4]{cai2012optimal}를 이용하여


\[
\| \overline{\mathbb{P}}_{1,0} \wedge \overline{\mathbb{P}}_{1,1}\| \ge \mathbb{E}_{(\gamma_{-1}, \lambda_{-1})}\left\{ \left\| \overline{\mathbb{P}}_{(1,1,\gamma_{-1}, \lambda_{-1})} \wedge \overline{\mathbb{P}}_{(1,0,\gamma_{-1}, \lambda_{-1})}  \right\| \right\}
\]
를 얻게 되므로, 증명이 마무리된다. \\


\end{quote}


\vspace{0.4cm}

이제 \eqref{16}을 얻기 위해  $(\gamma_{-1}, \lambda_{-1})$가 고정되었을 때 \eqref{16}에서  등장하는 각각의 측도 $\overline{\mathbb{P}}_{(1,0,\gamma_{-1}, \lambda_{-1})} $ 와 $\overline{\mathbb{P}}_{(1,1,\gamma_{-1}, \lambda_{-1})} $이 어떠한 형태인지 알 필요가 있다. 먼저 $\overline{\mathbb{P}}_{(1,0,\gamma_{-1}, \lambda_{-1})}$의 경우 $\gamma_1=0$으로 설정되어 있는데, 정의를 다시 떠올려본다면
\[
\overline{\mathbb{P}}_{(1,0,\gamma_{-1}, \lambda_{-1})} = \frac{1}{|\Theta_{(1,0,\gamma_{-1}, \lambda_{-1})}|} \sum_{\theta \in \Theta_{(1,0,\gamma_{-1}, \lambda_{-1})}} \mathbb{P}_\theta
\]
이고 $\mathbb{P}_\theta$는 p차원 정규분포 $N_p(0,\Sigma(\theta))$를 따르는 $n$개의 표본 $X_1, \dots, X_n$에 대한 결합분포이다. 이때 $(\gamma_{-1}, \lambda_{-1})$는 고정되어 있으니, $\theta\in\Theta_{(1,0,\gamma_{-1}, \lambda_{-1})}$에 대응하는 모든 $\Sigma(\theta)$들은 
\[
\Sigma(\theta) = I_p + \epsilon_{np} \sum_{m=2}^r \gamma_m A_m (\lambda_m),
\]
즉 $\theta$에 대응하는 $\lambda_1(\theta)$가 무슨 값을 취하더라도 $\Sigma(\theta)$는 동일한 형태라는 것이다. 따라서 $\overline{\mathbb{P}}_{(1,0,\gamma_{-1}, \lambda_{-1})}$는 $p$차원 정규분포 $N_p(0,\Sigma_0)$를 따르는 $n$개의 표본에 대한 결합분포임을 알 수 있으며 $\Sigma_0$는 다음과 같이 주어진다:
\[
\Sigma_0 := \left(\begin{array}{c|c} 1 & 0_{1\times(p-1)} \\ \hline 
0_{(p-1)\times 1} & S_{(p-1)\times (p-1)}\end{array} \right).
\]
여기서 $S_{(p-1)\times(p-1)} = \{s_{ij}\}$은 $(p-1)\times (p-1)$ 대칭행렬로
\[
s_{ij} = \left\{\begin{array}{ll} 1 & i=j\\
\epsilon_{np} & \gamma_{i+1} =\lambda_{i+1, j+1} = 1\\
0 & \mbox{otherwise} \end{array}\right.
\]
와 같이 주어진다. 여기서 $i=1, \dots, p-r = p-\lfloor p/2 \rfloor$에 대해 $\lambda_{mi}=0$이므로 $A_m(\lambda_m)$은 대각성분을 가지지 않기에,  $\epsilon_{np}$는  $S_{(p-1)\times(p-1)}$의 대각 성분에 나타나지 않음을 유념하자. \\

이제 $\overline{\mathbb{P}}_{(1,1,\gamma_{-1}, \lambda_{-1})}$의 경우를 살펴보도록 하자. 우선 임의의 $c \in \Lambda_{-1}$에 대해
\[
\Lambda_1(c) := \{a \in \mathbb{R}^p \ : \ \lambda_1(\theta) = a, \quad \lambda_{-1}(\theta) =c \ \mbox{ for some } \ \theta \in \Theta \}
\]
를 정의하자. 또한 $\lambda_{-1} = (\lambda_2 (\theta), \dots, \lambda_r(\theta))^T = \left(\begin{array}{c}\lambda_2(\theta)^T\\ \hline \vdots \\ \hline \lambda_r(\theta)^T \end{array}\right) \in \mathbb{R}^{(r-1)\times p}$가 하나 주어졌을 때, $n_{\lambda_{-1}}$를 $\lambda_{-1}$의 각 열의 성분을 모두 더했을 때 $2k$가 되는 열의 갯수라고 하자. 즉
\[
n_{\lambda_{-1}} := \left| \left\{ i \ : \ \sum_{m=2}^r \lambda_{mi} = 2k\right\}\right|
\]
이고 $p_{\lambda_{-1}} = r -n_{\lambda_{-1}}$이라 두자. 이와 같이 정의하면 $p_{\lambda_{-1}}$은 $\lambda_1$의 성분 $\lambda_{1i}$ 중 0이 될 수도, 1이 될 수도 있는 성분의 갯수라는 것을 알 수 있다. 여기서 임의의 $\lambda_{-1}\in \Lambda_{-1}$에 대해 
\[
|\Lambda_1(\lambda_{-1}) | = \binom{p_{\lambda_{-1}}}{k}, \quad p_{\lambda_{-1}} \ge \frac p4 -1
\]
가 성립함을 기억하자. 위 식의 오른쪽은 $n_{\lambda_{-1}} \cdot 2k \le r k$, 즉 $n_{\lambda_{-1}} \le r/2$임을 이용하면 유도할 수 있다:
\[
p_{\lambda_{-1}} = r - n_{\lambda_{-1}} \ge \frac r2  \ge \frac p4 -1.
\]
부등식 $n_{\lambda_{-1}} \cdot 2k \le r k$이 성립한다는 것은 좌변은 행렬  $\lambda_{-1} =  \left(\begin{array}{c}\lambda_2(\theta)^T\\ \hline \vdots \\ \hline \lambda_r(\theta)^T \end{array}\right) $에서  $n_{\lambda_{-1}}$에 해당하는 열들만 성분을 더한 것이고 우변은 행렬 $\lambda =  \left(\begin{array}{c}\lambda_1(\theta)^T\\ \hline 
 \lambda_{-1}(\theta)^T \end{array}\right)$의 모든 성분을 더한 것이라는 것을 생각해보면 자명하다. 그러므로 $p$가 충분히 크면 $\Lambda_1(\lambda_{-1})$은 공집합이 아니다. 이제 $\overline{\mathbb{P}}_{(1,1,\gamma_{-1}, \lambda_{-1})}$의 정의를 다시 떠올려보면
\[
\overline{\mathbb{P}}_{(1,1,\gamma_{-1}, \lambda_{-1})} = \frac{1}{|\Theta_{(1,1,\gamma_{-1}, \lambda_{-1})}|} \sum_{\theta \in \Theta_{(1,1,\gamma_{-1}, \lambda_{-1})}} \mathbb{P}_\theta
\]
이고 $\mathbb{P}_\theta$는 p차원 정규분포 $N_p(0,\Sigma(\theta))$를 따르는 $n$개의 표본 $X_1, \dots, X_n$에 대한 결합분포이다. 이때 $\theta\in\Theta_{(1,1,\gamma_{-1}, \lambda_{-1})}$에 대응하는 $\Sigma(\theta)$들은 
\[
\Sigma(\theta) = I_p + \epsilon_{np} A_m(\lambda_1(\theta)) + \epsilon_{np} \sum_{m=2}^r \gamma_m A_m (\lambda_m)
\]
의 형태로, 앞선 경우와는 다르게 $\theta$에 대응하는 $\lambda_1(\theta)$가 바뀔 때 마다 $\Sigma(\theta)$가 바뀐다는 것을 알 수 있다. 고를 수 있는 $\lambda_1(\theta)$의 갯수는 총 $\binom{p_{\lambda_{-1}}}{k}$개가 있으므로, 따라서 $\overline{\mathbb{P}}_{(1,1,\gamma_{-1}, \lambda_{-1})}$는 평균이 0이고 공분산 행렬이 다음과 같은 형태인 $p$차원 정규분포를 따르는 $n$개의 표본에 대한 결합분포들 $\binom{p_{\lambda_{-1}}}{k}$개의 평균임을 알 수 있다:
\[
 \left(\begin{array}{c|c} 1 & r^T \\ \hline 
r & S_{(p-1)\times (p-1)}\end{array} \right).
\]
이때 $r\in \mathbb{R}^{p-1}$은 0이 아닌 성분의 갯수가 $k$개이며 0이 아닌 성분들은 모두 $\epsilon_{np}$이고, $S_{(p-1)\times(p-1)}$은 앞서 정의한 것과 같다. \\

 이제 \cite[p.2411]{cai2012optimal}에서 사용한 논증을 이용한다.우선 \cite[Lemma 9]{cai2012optimal}로부터 다음을 알 수 있다: 각 $i=0,1,2$에 대해 $g_i$를 정규분포 $N(0,\Sigma_i)$의 확률밀도함수라 하자. 그러면

\[
\int \frac{g_1g_2}{g_0} = \left[ \mbox{det} (I - \Sigma_0^{-2}(\Sigma_1- \Sigma_0)(\Sigma_2-\Sigma_0)\right]^{-1/2}
\]
이다.\\

이때 주어진 $(\gamma_{-1}, \lambda_{-1})$에 대해식  \eqref{16}의 좌변에서 적분 $ \int \left(\frac{d\overline{\mathbb{P}}_{(1,1,\gamma_{-1}, \lambda_{-1})} }{d\overline{\mathbb{P}}_{(1,0,\gamma_{-1}, \lambda_{-1})} } \right)^2 d\overline{\mathbb{P}}_{(1,0,\gamma_{-1}, \lambda_{-1})}$을 생각해본다. 
 $\overline{\mathbb{P}}_{(1,0,\gamma_{-1}, \lambda_{-1})}$는 $p$차원 정규분포 $N_p(0,\Sigma_0)$를 따르는 $n$개의 i.i.d. 다변량 정규분포들에 대한 결합분포이고 $\overline{\mathbb{P}}_{(1,1,\gamma_{-1}, \lambda_{-1})}$는 $p$차원 정규분포를 따르는 $n$개의 표본에 대한 결합분포들 $\binom{p_{\lambda_{-1}}}{k}$개의 평균이다.  이제 $\lambda_1$과 $\lambda_1'$을  $\Lambda_1(\lambda_{-1})$에서 임의로 뽑고, 이들과 대응하는 공분산 행렬들을 각각 $\Sigma_1$과 $\Sigma_2$라 하자. $g_i$ ($i=0,1,2$)를 정규분포 $N_p(0,\Sigma_i)$의 확률밀도함수라 하면 적분 $ \int \left(\frac{d\overline{\mathbb{P}}_{(1,1,\gamma_{-1}, \lambda_{-1})} }{d\overline{\mathbb{P}}_{(1,0,\gamma_{-1}, \lambda_{-1})} } \right)^2 d\overline{\mathbb{P}}_{(1,0,\gamma_{-1}, \lambda_{-1})}$은 $\left( \int \frac{g_1 g_2}{g_0}\right)^n$ 형태의 적분들의 합으로 이루어진다는 것을 알 수 있다.  그래서 $R_{\lambda_1, \lambda_1'}^{\gamma_{-1}, \lambda_{-1}}$을
 
 \[
 R_{\lambda_1, \lambda_1'}^{\gamma_{-1}, \lambda_{-1}} := -\log \mbox{det}\left\{I_p - \Sigma_0^{-2}(\Sigma_0-\Sigma_1)(\Sigma_0-\Sigma_2) \right\}
 \]
와 같이 쓴다면, 식 \eqref{16}은 다음과 같이 쓸 수 있다.

\begin{equation}\label{18}\tag{18}
\begin{aligned}
&\mathbb{E}_{(\gamma_{-1}, \lambda_{-1})}\left\{ \int \left(\frac{d\overline{\mathbb{P}}_{(1,1,\gamma_{-1}, \lambda_{-1})} }{d\overline{\mathbb{P}}_{(1,0,\gamma_{-1}, \lambda_{-1})} } \right)^2 d\overline{\mathbb{P}}_{(1,0,\gamma_{-1}, \lambda_{-1})} -1 \right\}  \\
&= \mathbb{E}_{(\gamma_{-1}, \lambda_{-1})} \left[ \mathbb{E}_{(\lambda_1, \lambda_1')|\lambda_{-1}} \left\{\exp\left( \frac n2 R_{\lambda_1, \lambda_1'}^{\gamma_{-1}, \lambda_{-1}}\right) \right\}\right]\\
&= \mathbb{E}_{(\lambda_1, \lambda_1')}   \left[ \mathbb{E}_{(\gamma_{-1}, \lambda_{-1})|(\lambda_1, \lambda_1')}\left\{\exp\left( \frac n2 R_{\lambda_1, \lambda_1'}^{\gamma_{-1}, \lambda_{-1}}\right) \right\}\right].
\end{aligned}
\end{equation}
이때 $\lambda_1, \lambda_1' |\lambda_{-1} \overset{i.i.d}{\sim}\mbox{Unif}\{\Lambda_1(\lambda_{-1})\}$, $(\gamma_{-1}, \lambda_{-1})|(\lambda_1, \lambda_1') \sim \mbox{Unif}\{ \Theta_{-1}(\lambda_1, \lambda_1')\}$와 같은 분포가 주어져 있다고 생각하며, $\Theta_{-1}(\cdot, \cdot)$은

\[
\Theta_{-1}(a_1, a_2) := \{0,1\}^{r-1} \times \{c \in \Lambda_{-1} \ : \ \exists \theta_i \in \Theta, \ i=1,2, \ \mbox{ s.t. } \ \lambda_1(\theta_i)= a_i, \ \lambda_{-1}(\theta_i) = c \}
\]
와 같이 주어져있다. Lemma 6의 결과를 이용하면 식 \eqref{18}은 아래의 식에 의해 유계이다:

\begin{equation}\label{20}\tag{20}
\begin{aligned}
\mathbb{E}_J &\left[\exp \left\{-n \log (1 -J\epsilon_{np}^2) \right\}\mathbb{E}_{(\lambda_1, \lambda_1')|J} \left\{ \mathbb{E}_{(\gamma_{-1}, \lambda_{-1})|(\lambda_1, \lambda_1')}\exp\left(\frac n2 R_{1,\lambda_1,\lambda_1'}^{\gamma_{-1}, \lambda_{-1}} \right)\right\} \right]\\
&\le \mathbb{E}_J\left[\exp\left\{ -n\log (1- J\epsilon_{np}^2)\right\}\frac32 -1 \right].
\end{aligned}
\end{equation}
여기서 $J$는 $\lambda_1$과 $\lambda_1'$에서 0이 아닌 성분이 같은 위치에 몇개나 있는지를 센 숫자를 뜻한다. 즉, $J = \lambda_1^T \lambda_1'$이다. $\lambda_1, \lambda_1' |\lambda_{-1} \overset{i.i.d}{\sim}\mbox{Unif}\{\Lambda_1(\lambda_{-1})\}$임을 이용하면 각 $j=0, \dots, k$마다
\[
\mathbb{E}_J \{ I(J=j) | \lambda_{-1} \} = \frac{\binom{k}{j} \binom{p_{\lambda_{-1}}-k }{k-j}}{\binom{p_{\lambda_{-1}}}{k}} = \left(\frac{k!}{(k-j)!}\right)^2 \frac{\{(p_{\lambda_{-1}}-k)! \}^2}{p_{\lambda_{-1}}! (p_{\lambda_{-1}} -2k +j)!} \frac{1}{j!} \le \left( \frac{k^2}{p_{\lambda_{-1}} -k}\right)^j
\]
임을 얻게 된다. 그러므로 모든 $\lambda_{-1}$에 대해 $p_{\lambda_{-1}} \ge p/4-1$가 성립한다는 것을 이용하면
\[
\mathbb{E}_J I (J=j) = \mathbb{E}_{\lambda_{-1}} \left[\mathbb{E}_J \left\{ I(J=j) | \lambda_{-1}\right\}\right] \le \mathbb{E}_{\lambda_{-1}}\left\{ \left( \frac{k^2}{p_{\lambda_{-1}} -k}\right)^j\right\} \le \left( \frac{k^2}{p/4-1-k}\right)^j
\]
를 얻는다. 따라서, 식 \eqref{20}은 $p$가 충분히 크다면 다음 식에 의해 유계이다:

\[\begin{aligned}
\sum_{j=0}^k &\left(\frac{k^2}{p/4-1-k} \right)^j \left[\exp\left\{ -n\log(1-j \epsilon_{np}^2)\right\}\frac 32 -1 \right]\\
&= \frac12 + \sum_{j=1}^k \left(\frac{k^2}{p/4-1-k} \right)^j \left[\exp\left\{ -n\log(1-j \epsilon_{np}^2)\right\}\frac 32 -1 \right]\\
&\le \frac12 + \frac32 \left(\frac{k^2}{p/4-1-k} \right)^j  p^{2\nu^2 j} \le  \frac12 + \frac{3C}{2} p^{-\epsilon j}p^{(\epsilon/2) j} \le c_2^2,
\end{aligned}\]
이때 $C>0$는 상수이고 $c_2^2 = 3/4 <1$이며, 두번째 부등식은 $s_0^2 = O(p^{3-\epsilon})$과 $\nu = \sqrt{\epsilon/4}$임을 이용하면 얻을 수 있다. 이로써 (13)식에 대한 증명이 마무리되었다.
